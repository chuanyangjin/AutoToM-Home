@inproceedings{jin2024mmtom,
  title={MMToM-QA: Multimodal Theory of Mind Question Answering},
  author={Jin, Chuanyang and Wu, Yutong and Cao, Jing and Xiang, Jiannan and Kuo, Yen-Ling and Hu, Zhiting and Ullman, Tomer and Torralba, Antonio and Tenenbaum, Joshua B. and Shu, Tianmin},
  booktitle={62nd Annual Meeting of the Association for Computational Linguistics (ACL)}, 
  year={2024}
}

@article{shi2024muma,
  title={MuMA-ToM: Multi-modal Multi-Agent Theory of Mind},
  author={Shi, Haojun and Ye, Suyu and Fang, Xinyu and Jin, Chuanyang and Isik, Leyla and Kuo, Yen-Ling and Shu, Tianmin},
  journal={arXiv preprint arXiv:2408.12574},
  year={2024}
}

@inproceedings{le2019revisiting,
  title={Revisiting the Evaluation of Theory of Mind through Question Answering},
  author={Le, Matthew and Boureau, Y-Lan and Nickel, Maximilian},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={5872--5877},
  year={2019}
}

@article{gandhi2024understanding,
  title={Understanding Social Reasoning in Language Models with Language Models},
  author={Gandhi, Kanishk and Fr{\"a}nken, Jan-Philipp and Gerstenberg, Tobias and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{he2023hi,
  title={HI-TOM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models},
  author={He, Yinghui and Wu, Yufan and Jia, Yilin and Mihalcea, Rada and Chen, Yulong and Deng, Naihao},
  journal={arXiv preprint arXiv:2310.16755},
  year={2023}
}

@article{baker2009action,
  title={Action Understanding as Inverse Planning},
  author={Baker, Chris L and Saxe, Rebecca and Tenenbaum, Joshua B},
  journal={Cognition},
  volume={113},
  number={3},
  pages={329--349},
  year={2009},
  publisher={Elsevier}
}




@article{wilf2023think,
  title={Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities},
  author={Wilf, Alex and Lee, Sihyun Shawn and Liang, Paul Pu and Morency, Louis-Philippe},
  journal={62nd Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2024}
}

@article{sclar2023minding,
  title={Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker},
  author={Sclar, Melanie and Kumar, Sachin and West, Peter and Suhr, Alane and Choi, Yejin and Tsvetkov, Yulia},
  journal={61st Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2023}
}

@article{hou2024timetom,
  title={TimeToM: Temporal Space is the Key to Unlocking the Door of Large Language Models' Theory-of-Mind},
  author={Hou, Guiyang and Zhang, Wenqi and Shen, Yongliang and Wu, Linjuan and Lu, Weiming},
  journal={arXiv preprint arXiv:2407.01455},
  year={2024}
}